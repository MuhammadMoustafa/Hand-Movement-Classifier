{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@author: Muhammad Moustafa\n",
    "\n",
    "naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io as sio\n",
    "from scipy.signal import iirfilter\n",
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the data from the matlab files \n",
    "# the function takes the name of the 2 files as paramters\n",
    "# and return a np array contains the data of each file \n",
    "\n",
    "def read_data(file_name_1 , file_name_2) :\n",
    "    return np.array(sio.loadmat(file_name_1 ,  appendmat=True)[file_name_1]) , np.array(sio.loadmat(file_name_2 ,  appendmat=True)[file_name_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filterate the input data from the 50 hz noise    \n",
    "# the function takes the np array and the sampling frequency as paramters\n",
    "# and return a filtered np array \n",
    "def imp_filter(file,fs,freqLow=47,freqHigh=53,order = 3):\n",
    "\n",
    "    nyq = fs/2.0\n",
    "    freqLow /= nyq\n",
    "    freqHigh /=nyq\n",
    "    b, a = scipy.signal.iirfilter(order, [freqLow, freqHigh], btype='bandstop',analog=False)\n",
    "    filteredRecord= scipy.signal.lfilter(b, a, file)\n",
    "    return filteredRecord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the Energy feature for the file \n",
    "# the function takes a np array as a paramter\n",
    "# and return an 1D np array contains the Energy of each record \n",
    "def Energy (file) :\n",
    "    energy = (file**2).sum(axis=1) # sum the row after squaring each reading\n",
    "    return energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the Power feature for the file \n",
    "# the function takes a np array as a paramter\n",
    "# and return an 1D np array contains the Power of each record \n",
    "\n",
    "def Power (file):\n",
    "    power = (file**4).sum(axis=1) # sum the row after calculating the 4th power for each reading\n",
    "    return power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the Non Linear Energy feature for the file \n",
    "# the function takes a np array as a paramter\n",
    "# and return an 1D np array contains the Non Linear Energy of each record \n",
    "\n",
    "def NonLinearEnergy (file):\n",
    "    nonlinearenergy = np.zeros((file.shape[0])) # intialize an 1D zero array\n",
    "    for i in range (file.shape[0]): # for each row\n",
    "        for j in range (file.shape[1]-2):# for each column except for the last 2 clolumns\n",
    "            nonlinearenergy[i] += -file[i,j+2]*file[i,j] + file[i,j+1]**2 # calculate the summation \n",
    "    return nonlinearenergy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the Curve Length feature for the file \n",
    "# the function takes a np array as a paramter\n",
    "# and return an 1D np array contains the Curve Length of each record\n",
    "\n",
    "def CurveLength (file):\n",
    "    curvelength = np.zeros((file.shape[0])) # intialize an 1D zero array\n",
    "    for i in range (file.shape[0]): # for each row\n",
    "        for j in range (0,file.shape[1]-2):# for each column except for the last clolumn \n",
    "            curvelength[i] += file[i,j+1] - file[i,j] # calculate the summation \n",
    "            \n",
    "    return curvelength    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the normal distribution of each feature in each file \n",
    "# the function takes the number of rows to tarin the model with as a paramter\n",
    "# and return a list contains the noraml distribution of each file  \n",
    "def learn_phase(learn_size) :\n",
    "    \n",
    "    # intialize a 2D zero array to store the features of the learning set for each file\n",
    "    file1_learn_Features = np.zeros((learn_size,4))    \n",
    "    file2_learn_Features = np.zeros((learn_size,4))\n",
    "\n",
    "    # filterate the data\n",
    "    file1_learn_set = imp_filter(input1 , int(input1_fs))[0:learn_size] \n",
    "    file2_learn_set = imp_filter(input2 , int(input2_fs))[0:learn_size]\n",
    "\n",
    "    # calculate the features for each file\n",
    "\n",
    "    file1_learn_Features[:,0] = Energy(file1_learn_set)        \n",
    "    file2_learn_Features[:,0] = Energy(file2_learn_set)\n",
    "    \n",
    "    file1_learn_Features[:,1] = Power(file1_learn_set)\n",
    "    file2_learn_Features[:,1] = Power(file2_learn_set)\n",
    "    \n",
    "    file1_learn_Features[:,2] = NonLinearEnergy(file1_learn_set)\n",
    "    file2_learn_Features[:,2] = NonLinearEnergy(file2_learn_set)\n",
    "    \n",
    "    file1_learn_Features[:,3] = CurveLength(file1_learn_set)\n",
    "    file2_learn_Features[:,3] = CurveLength(file2_learn_set)\n",
    "        \n",
    "    file1_learn_features_mean = np.mean(file1_learn_Features,axis=0)\n",
    "    file2_learn_features_mean = np.mean(file2_learn_Features,axis=0)\n",
    "    file1_learn_features_std = np.std(file1_learn_Features,axis=0)\n",
    "    file2_learn_features_std = np.std(file2_learn_Features,axis=0)\n",
    "\n",
    "    # intialize an empty list to store the normal distributions\n",
    "    file1_norm_dist = [] \n",
    "    file2_norm_dist = []\n",
    "\n",
    "    # calulate the mean and the standard deviation of each feature and append the noraml distribution to the list\n",
    "    for i in range (4):\n",
    "        file1_norm_dist.append(norm(file1_learn_features_mean[i],file1_learn_features_std[i]))\n",
    "        file2_norm_dist.append(norm(file2_learn_features_mean[i],file2_learn_features_std[i]))            \n",
    "    \n",
    "    return file1_norm_dist , file2_norm_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the normal distribution of each feature in each file \n",
    "# the function takes the number of rows to tarin the model with as a paramter .. so it can get the #rows to test\n",
    "# and return a np array contains the features of each file \n",
    "def test_phase(learn_size):\n",
    "    \n",
    "    # calculate the number of test rows\n",
    "    test_size = input1.shape[0] - learn_size\n",
    "    \n",
    "    # intialize a 2D zeor array to store the features of the test set\n",
    "    file1_test_Features = np.zeros((test_size,4))    \n",
    "    file2_test_Features = np.zeros((test_size,4))\n",
    "\n",
    "    # filterate the data\n",
    "    file1_test_set = imp_filter(input1 , int(input1_fs))[0+learn_size:test_size+learn_size] \n",
    "    file2_test_set = imp_filter(input2 , int(input2_fs))[0+learn_size:test_size+learn_size]\n",
    "\n",
    "    # calculate the features for file#1 test set\n",
    "    # calculate the features for file#2 test set  \n",
    "    \n",
    "    file1_test_Features[:,0] = Energy(file1_test_set)\n",
    "    file1_test_Features[:,1] = Power(file1_test_set)\n",
    "    file1_test_Features[:,2] = NonLinearEnergy(file1_test_set)\n",
    "    file1_test_Features[:,3] = CurveLength(file1_test_set)    \n",
    "            \n",
    "    file2_test_Features[:,0] = Energy(file2_test_set)\n",
    "    file2_test_Features[:,1] = Power(file2_test_set)\n",
    "    file2_test_Features[:,2] = NonLinearEnergy(file2_test_set)\n",
    "    file2_test_Features[:,3] = CurveLength(file2_test_set)          \n",
    "            \n",
    "    return file1_test_Features , file2_test_Features        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_performance():\n",
    "    \n",
    "    # get the noraml distribution of each feature in each file\n",
    "    input1_norm , input2_norm = learn_phase(input_learn_size)\n",
    "    # get the features of the test data set in each file\n",
    "    input1_test , input2_test = test_phase(input_learn_size)\n",
    "    \n",
    "    # intailaize variables to calculate the accuracy of the model\n",
    "    file1_acc = 0.0\n",
    "    file2_acc = 0.0\n",
    "    '''\n",
    "    boolLateral = []\n",
    "    boolPalmar = []\n",
    "   '''\n",
    "    \n",
    "    # test the data in file#1\n",
    "    #if the data abeied the normal distribution of file 1 then increase accuracy by 1  \n",
    "    for i in range (input_test_size): #for each record\n",
    "        \n",
    "        # calculate the likelyhood of the record in file 1 to be in file 1\n",
    "        ainput1= input1_norm[0].pdf(input1_test[i,0])*input1_norm[1].pdf(input1_test[i,1])*input1_norm[2].pdf(input1_test[i,2])*input1_norm[3].pdf(input1_test[i,3])\n",
    "        \n",
    "        # calculate the likelyhood of the record in file 1 to be in file 2\n",
    "        ainput2=input2_norm[0].pdf(input1_test[i,0])*input2_norm[1].pdf(input1_test[i,1])*input2_norm[2].pdf(input1_test[i,2])*input2_norm[3].pdf(input1_test[i,3])\n",
    "        \n",
    "        # calculate the likelyhood of the record in file 2 to be in file 1\n",
    "        binput1= input1_norm[0].pdf(input2_test[i,0])*input1_norm[1].pdf(input2_test[i,1])*input1_norm[2].pdf(input2_test[i,2])*input1_norm[3].pdf(input2_test[i,3])\n",
    "        \n",
    "        # calculate the likelyhood of the record in file 2 to be in file 2\n",
    "        binput2=input2_norm[0].pdf(input2_test[i,0])*input2_norm[1].pdf(input2_test[i,1])*input2_norm[2].pdf(input2_test[i,2])*input2_norm[3].pdf(input2_test[i,3])\n",
    "       \n",
    "        if (ainput1 > ainput2): # if the propabilty of that record in file 1 to be in file 1 is more\n",
    "            '''\n",
    "            boolLateral.append(True)\n",
    "            '''\n",
    "            file1_acc +=1 # increase the accuracy by one\n",
    "        \n",
    "        '''\n",
    "        else:\n",
    "            boolLateral.append(False)\n",
    "        '''\n",
    "        \n",
    "        if (binput1 < binput2): # if the propabilty of that record in file 2 to be in file 2 is more\n",
    "            '''\n",
    "            #boolPalmar.append(True)\n",
    "            '''\n",
    "            file2_acc +=1\n",
    "        '''\n",
    "        else:\n",
    "            boolPalmar.append(False)\n",
    "        ''' \n",
    "    \n",
    "    print (\"\\nAccuracy is \" , (file1_acc + file2_acc)*100.0/(2*input_test_size) , \"%\") # print the total Accuracy\n",
    "    '''\n",
    "    print (file1_acc,boolLateral\"\\n\" , file2_acc , boolPalmar)\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program is made to differentiate between two types on movement 'palmar' and 'lateral' based on EMG records based on naive bayes classifier\n",
      "please make sure that the 2 matlab files have the same shape\n",
      "please make sure that the 2 matlab file are in the same directory that the program on or write the full path instead of the file name\n",
      "\n",
      "write 1 for Biostatistics Project\n",
      "write anything else to write your files' name\n",
      "write exit to close the program\n",
      "\n",
      "1\n",
      "Write 1 to shuffle the data\n",
      "any thing else to continue without shuffle\n",
      "12\n",
      "\n",
      "Accuracy is  79.0 %\n",
      "\n",
      "write 1 for Biostatistics Project\n",
      "write anything else to write your files' name\n",
      "write exit to close the program\n",
      "\n",
      "exit\n",
      "Thank You!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''    \n",
    "user interface    \n",
    "'''\n",
    "# intailaize a boolean variable to run the program multiple times \n",
    "exiit = True\n",
    "print(\"This program is made to differentiate between two types on movement 'palmar' and 'lateral' based on EMG records based on naive bayes classifier\")\n",
    "print(\"please make sure that the 2 matlab files have the same shape\")\n",
    "print(\"please make sure that the 2 matlab file are in the same directory that the program on or write the full path instead of the file name\")\n",
    "\n",
    "while (exiit):\n",
    "    try:\n",
    "        select = input(\"\\nwrite 1 for Biostatistics Project\\nwrite anything else to write your files' name\\nwrite exit to close the program\\n\\n\")\n",
    "        if select == '1' :\n",
    "            while(True):\n",
    "                try:\n",
    "                    input1 , input2 = read_data('lateral' , 'palmar')\n",
    "                    input1_fs = 1000\n",
    "                    input2_fs = 1000\n",
    "                    input_learn_size = 100\n",
    "                    input_test_size = 50\n",
    "                    select2 = input(\"Write 1 to shuffle the data\\nany thing else to continue without shuffle\\n\") #use shuffle or not\n",
    "                    if select2 == '1':\n",
    "                        np.random.shuffle(input1)\n",
    "                        np.random.shuffle(input2)\n",
    "                    calculate_performance()\n",
    "                except FileNotFoundError:\n",
    "                    print(\"file not found\\nplease make sure that the 2 matlab file are in the same directory that the program on or write the full path instead of the file name\\n\")                      \n",
    "                finally:\n",
    "                    break\n",
    "\n",
    "    \n",
    "        elif select == 'exit':\n",
    "            exiit = False     \n",
    "    \n",
    "        else : \n",
    "\n",
    "            # get the data file name , sampling frequency from the user and pass them to their functions to store and filterate\n",
    "            while(True):\n",
    "                try:\n",
    "                    input1 , input2 = read_data(input('insert the name of file#1 with out the extention .mat\\n '), input('insert the name of file#2 with out the extention .mat\\n '))    \n",
    "                    break\n",
    "                except FileNotFoundError:\n",
    "                    print(\"file not found\\nplease make sure that the 2 matlab file are in the same directory that the program on or write the full path instead of the file name\\n\")\n",
    "                    \n",
    "                \n",
    "            while(True):\n",
    "                input1_fs = input(\"write the sampling frequency of the first record\\n\")\n",
    "                input2_fs = input(\"write the sampling frequency of the second record\\n\")\n",
    "                if(input1_fs.isdigit() and input2_fs.isdigit() and int(input1_fs) > 105 and int(input2_fs) >105 ): \n",
    "                    break\n",
    "                else :\n",
    "                    print(\"\\ncheck the written sampling frequency\\n\")\n",
    "                \n",
    "            # shuffle the files\n",
    "            np.random.shuffle(input1)\n",
    "            np.random.shuffle(input2)\n",
    "        \n",
    "            # get the learn size test\n",
    "            while(True):\n",
    "                temp = input(\"write the percentage you want to train the model with 'any number between 0 and 100' \\n\")\n",
    "                try :  \n",
    "                    if ( 0< float(temp) <100 ):\n",
    "                        input_learn_size = int((np.ceil( input1.shape[0] * float(temp))) / 100.0)\n",
    "                        break   \n",
    "                except ValueError:\n",
    "                    print(\"\\ncheck the written percentage\\n\")\n",
    "                    \n",
    "            input_test_size = input1.shape[0] - input_learn_size\n",
    "            calculate_performance()\n",
    "    except:\n",
    "        raise\n",
    "print (\"Thank You!!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
